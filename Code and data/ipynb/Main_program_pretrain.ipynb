{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n----------------------------------------------------------------------------------\nThis file is Data_processing_pretrain_final.py\n\nImporting functions.......\n\n\n----------------------------------------------------------------------------------\nThis draw_label_final.py\n\nImporting functions.......\n\n\nSucessfully import draw_label_final.py!\n-------------------------------------------------------------------------------\n\n\n# function read_image(file_path), which returns image and label in the dictionary datatype\n \n\n# function imshow(image, label), which shows two images in grayscale\n\n\n# function datapreprocessing(image, label, resize), which finishs the preprocessing.\n  Note that resize is True or False\n\n\n# function transfer_to_train_data(image, input_shape), which prepares the train_x data for model  \n\n\n# three_floder_validation(image, label), which classifies the data to three floder.\n  It returns floder1, floder2, floder3\n\n\nSucessfully import Data_processing_pretrain_final.py!\n-------------------------------------------------------------------------------\n\n"
    }
   ],
   "source": [
    "from Data_processing_pretrain_final import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "\n----------------------------------------------------------------------------------\nThis file is semantic_Unet_pretrain.py\n\nImporting model.......\n\n\n\n# use function checkpoint(save_name) for saving best weighting.\n# use class History() for creating a object which saves loss and accuracy.\n# use callbacks = [checkpoint, history]\n\n\n\n# use model = u_net(input_shape) to create a mode.\n\nSucessfully import semantic_Unet_pretrain.py!\n\n-------------------------------------------------------------------------------\n\n"
    }
   ],
   "source": [
    "from semantic_Unet_pretrain import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Function three_floder_validation finish!\n\n"
    }
   ],
   "source": [
    "image, label = read_image(\"data\")\n",
    "floder1, floder2, floder3 = three_floder_validation(image,label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Floder1 (train : f01, f02 , test : f03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = floder1[0], floder1[1], floder1[2], floder1[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "preprocessing....\n\ndealing with image....\n\npreprocessing for image finish!\n\ndealing with label....\n\nlabel_to_class_label finish!\n\nFunction label_to_1Hlabel finish!\n\npreprocessing for label finish!\n\n"
    }
   ],
   "source": [
    "train_x, train_y = datapreprocessing(train_x, train_y, resize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "preprocessing....\n\ndealing with image....\n\npreprocessing for image finish!\n\ndealing with label....\n\nlabel_to_class_label finish!\n\nFunction label_to_1Hlabel finish!\n\npreprocessing for label finish!\n\n"
    }
   ],
   "source": [
    "test_x, test_y = datapreprocessing(test_x, test_y, resize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Function transfer_to_train_data finish!\n\n"
    }
   ],
   "source": [
    "train_x = transfer_to_train_data(train_x, (train_x.shape[0], train_x.shape[1],train_x.shape[2],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Function transfer_to_train_data finish!\n\n"
    }
   ],
   "source": [
    "test_x = transfer_to_train_data(test_x, (test_x.shape[0], test_x.shape[1],test_x.shape[2],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = History()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_back = [checkpoint, history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput (InputLayer)              (None, 672, 224, 1)  0                                            \n__________________________________________________________________________________________________\nc_1_conv1 (Conv2D)              (None, 672, 224, 16) 1312        input[0][0]                      \n__________________________________________________________________________________________________\nc_1_BN1 (BatchNormalization)    (None, 672, 224, 16) 64          c_1_conv1[0][0]                  \n__________________________________________________________________________________________________\nc_1_conv2 (Conv2D)              (None, 672, 224, 16) 20752       c_1_BN1[0][0]                    \n__________________________________________________________________________________________________\nc_1_BN2 (BatchNormalization)    (None, 672, 224, 16) 64          c_1_conv2[0][0]                  \n__________________________________________________________________________________________________\nc_1_maxpool1 (MaxPooling2D)     (None, 336, 112, 16) 0           c_1_BN2[0][0]                    \n__________________________________________________________________________________________________\nc_2_conv1 (Conv2D)              (None, 336, 112, 32) 41504       c_1_maxpool1[0][0]               \n__________________________________________________________________________________________________\nc_2_BN1 (BatchNormalization)    (None, 336, 112, 32) 128         c_2_conv1[0][0]                  \n__________________________________________________________________________________________________\nc_2_conv2 (Conv2D)              (None, 336, 112, 32) 82976       c_2_BN1[0][0]                    \n__________________________________________________________________________________________________\nc_2_BN2 (BatchNormalization)    (None, 336, 112, 32) 128         c_2_conv2[0][0]                  \n__________________________________________________________________________________________________\nc_2_maxpool1 (MaxPooling2D)     (None, 168, 56, 32)  0           c_2_BN2[0][0]                    \n__________________________________________________________________________________________________\nc_3_conv1 (Conv2D)              (None, 168, 56, 64)  165952      c_2_maxpool1[0][0]               \n__________________________________________________________________________________________________\nc_3_BN1 (BatchNormalization)    (None, 168, 56, 64)  256         c_3_conv1[0][0]                  \n__________________________________________________________________________________________________\nc_3_conv2 (Conv2D)              (None, 168, 56, 64)  331840      c_3_BN1[0][0]                    \n__________________________________________________________________________________________________\nc_3_BN2 (BatchNormalization)    (None, 168, 56, 64)  256         c_3_conv2[0][0]                  \n__________________________________________________________________________________________________\nc_3_maxpool1 (MaxPooling2D)     (None, 84, 28, 64)   0           c_3_BN2[0][0]                    \n__________________________________________________________________________________________________\nc_4_conv1 (Conv2D)              (None, 84, 28, 128)  663680      c_3_maxpool1[0][0]               \n__________________________________________________________________________________________________\nc_4_BN1 (BatchNormalization)    (None, 84, 28, 128)  512         c_4_conv1[0][0]                  \n__________________________________________________________________________________________________\nc_4_conv2 (Conv2D)              (None, 84, 28, 128)  1327232     c_4_BN1[0][0]                    \n__________________________________________________________________________________________________\nc_4_BN2 (BatchNormalization)    (None, 84, 28, 128)  512         c_4_conv2[0][0]                  \n__________________________________________________________________________________________________\nc_4_maxpool1 (MaxPooling2D)     (None, 42, 14, 128)  0           c_4_BN2[0][0]                    \n__________________________________________________________________________________________________\nb_conv1 (Conv2D)                (None, 42, 14, 256)  2654464     c_4_maxpool1[0][0]               \n__________________________________________________________________________________________________\nb_BN1 (BatchNormalization)      (None, 42, 14, 256)  1024        b_conv1[0][0]                    \n__________________________________________________________________________________________________\nb_conv2 (Conv2D)                (None, 42, 14, 256)  5308672     b_BN1[0][0]                      \n__________________________________________________________________________________________________\nb_BN2 (BatchNormalization)      (None, 42, 14, 256)  1024        b_conv2[0][0]                    \n__________________________________________________________________________________________________\ne_1_Tconv (Conv2DTranspose)     (None, 84, 28, 128)  2654336     b_BN2[0][0]                      \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 84, 28, 256)  0           c_4_BN2[0][0]                    \n                                                                 e_1_Tconv[0][0]                  \n__________________________________________________________________________________________________\ne_1_conv1 (Conv2D)              (None, 84, 28, 128)  2654336     concatenate[0][0]                \n__________________________________________________________________________________________________\ne_1_BN1 (BatchNormalization)    (None, 84, 28, 128)  512         e_1_conv1[0][0]                  \n__________________________________________________________________________________________________\ne_1_conv2 (Conv2D)              (None, 84, 28, 128)  1327232     e_1_BN1[0][0]                    \n__________________________________________________________________________________________________\ne_1_BN2 (BatchNormalization)    (None, 84, 28, 128)  512         e_1_conv2[0][0]                  \n__________________________________________________________________________________________________\ne_2_Tconv (Conv2DTranspose)     (None, 168, 56, 64)  663616      e_1_BN2[0][0]                    \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 168, 56, 128) 0           c_3_BN2[0][0]                    \n                                                                 e_2_Tconv[0][0]                  \n__________________________________________________________________________________________________\ne_2_conv1 (Conv2D)              (None, 168, 56, 64)  663616      concatenate_1[0][0]              \n__________________________________________________________________________________________________\ne_2_BN1 (BatchNormalization)    (None, 168, 56, 64)  256         e_2_conv1[0][0]                  \n__________________________________________________________________________________________________\ne_2_conv2 (Conv2D)              (None, 168, 56, 64)  331840      e_2_BN1[0][0]                    \n__________________________________________________________________________________________________\ne_2_BN2 (BatchNormalization)    (None, 168, 56, 64)  256         e_2_conv2[0][0]                  \n__________________________________________________________________________________________________\ne_3_Tconv (Conv2DTranspose)     (None, 336, 112, 32) 165920      e_2_BN2[0][0]                    \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 336, 112, 64) 0           c_2_BN2[0][0]                    \n                                                                 e_3_Tconv[0][0]                  \n__________________________________________________________________________________________________\ne_3_conv1 (Conv2D)              (None, 336, 112, 32) 165920      concatenate_2[0][0]              \n__________________________________________________________________________________________________\ne_3_BN1 (BatchNormalization)    (None, 336, 112, 32) 128         e_3_conv1[0][0]                  \n__________________________________________________________________________________________________\ne_3_conv2 (Conv2D)              (None, 336, 112, 32) 82976       e_3_BN1[0][0]                    \n__________________________________________________________________________________________________\ne_3_BN2 (BatchNormalization)    (None, 336, 112, 32) 128         e_3_conv2[0][0]                  \n__________________________________________________________________________________________________\ne_4_Tconv (Conv2DTranspose)     (None, 672, 224, 16) 41488       e_3_BN2[0][0]                    \n__________________________________________________________________________________________________\nconcatenate_3 (Concatenate)     (None, 672, 224, 32) 0           c_1_BN2[0][0]                    \n                                                                 e_4_Tconv[0][0]                  \n__________________________________________________________________________________________________\ne_4_conv1 (Conv2D)              (None, 672, 224, 16) 41488       concatenate_3[0][0]              \n__________________________________________________________________________________________________\ne_4_BN1 (BatchNormalization)    (None, 672, 224, 16) 64          e_4_conv1[0][0]                  \n__________________________________________________________________________________________________\ne_4_conv2 (Conv2D)              (None, 672, 224, 16) 20752       e_4_BN1[0][0]                    \n__________________________________________________________________________________________________\ne_4_BN2 (BatchNormalization)    (None, 672, 224, 16) 64          e_4_conv2[0][0]                  \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 672, 224, 2)  34          e_4_BN2[0][0]                    \n==================================================================================================\nTotal params: 19,417,826\nTrainable params: 19,414,882\nNon-trainable params: 2,944\n__________________________________________________________________________________________________\nNone\n"
    }
   ],
   "source": [
    "unet_f1 = u_net((672,224,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "_coef: 0.9973 - val_loss: 0.0315 - val_dice_coef: 0.9685\n\nEpoch 00300: val_loss did not improve from 0.03090\nEpoch 301/400\n40/40 [==============================] - 4s 102ms/step - loss: 0.0027 - dice_coef: 0.9973 - val_loss: 0.0314 - val_dice_coef: 0.9686\n\nEpoch 00301: val_loss did not improve from 0.03090\nEpoch 302/400\n40/40 [==============================] - 4s 101ms/step - loss: 0.0028 - dice_coef: 0.9972 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00302: val_loss did not improve from 0.03090\nEpoch 303/400\n40/40 [==============================] - 5s 115ms/step - loss: 0.0028 - dice_coef: 0.9972 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00303: val_loss did not improve from 0.03090\nEpoch 304/400\n40/40 [==============================] - 4s 98ms/step - loss: 0.0027 - dice_coef: 0.9973 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00304: val_loss did not improve from 0.03090\nEpoch 305/400\n40/40 [==============================] - 4s 105ms/step - loss: 0.0027 - dice_coef: 0.9973 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00305: val_loss did not improve from 0.03090\nEpoch 306/400\n40/40 [==============================] - 4s 100ms/step - loss: 0.0027 - dice_coef: 0.9973 - val_loss: 0.0314 - val_dice_coef: 0.9686\n\nEpoch 00306: val_loss did not improve from 0.03090\nEpoch 307/400\n40/40 [==============================] - 4s 101ms/step - loss: 0.0027 - dice_coef: 0.9973 - val_loss: 0.0314 - val_dice_coef: 0.9686\n\nEpoch 00307: val_loss did not improve from 0.03090\nEpoch 308/400\n40/40 [==============================] - 4s 111ms/step - loss: 0.0027 - dice_coef: 0.9973 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00308: val_loss did not improve from 0.03090\nEpoch 309/400\n40/40 [==============================] - 4s 98ms/step - loss: 0.0028 - dice_coef: 0.9972 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00309: val_loss did not improve from 0.03090\nEpoch 310/400\n40/40 [==============================] - 4s 101ms/step - loss: 0.0028 - dice_coef: 0.9972 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00310: val_loss did not improve from 0.03090\nEpoch 311/400\n40/40 [==============================] - 5s 119ms/step - loss: 0.0028 - dice_coef: 0.9972 - val_loss: 0.0316 - val_dice_coef: 0.9684\n\nEpoch 00311: val_loss did not improve from 0.03090\nEpoch 312/400\n40/40 [==============================] - 4s 96ms/step - loss: 0.0028 - dice_coef: 0.9972 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00312: val_loss did not improve from 0.03090\nEpoch 313/400\n40/40 [==============================] - 4s 101ms/step - loss: 0.0028 - dice_coef: 0.9972 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00313: val_loss did not improve from 0.03090\nEpoch 314/400\n40/40 [==============================] - 4s 107ms/step - loss: 0.0028 - dice_coef: 0.9972 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00314: val_loss did not improve from 0.03090\nEpoch 315/400\n40/40 [==============================] - 4s 110ms/step - loss: 0.0028 - dice_coef: 0.9972 - val_loss: 0.0315 - val_dice_coef: 0.9685\n\nEpoch 00315: val_loss did not improve from 0.03090\nEpoch 316/400\n40/40 [==============================] - 4s 97ms/step - loss: 0.0027 - dice_coef: 0.9973 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00316: val_loss did not improve from 0.03090\nEpoch 317/400\n40/40 [==============================] - 4s 103ms/step - loss: 0.0027 - dice_coef: 0.9973 - val_loss: 0.0317 - val_dice_coef: 0.9683\n\nEpoch 00317: val_loss did not improve from 0.03090\nEpoch 318/400\n40/40 [==============================] - 4s 111ms/step - loss: 0.0027 - dice_coef: 0.9973 - val_loss: 0.0314 - val_dice_coef: 0.9686\n\nEpoch 00318: val_loss did not improve from 0.03090\nEpoch 319/400\n40/40 [==============================] - 4s 98ms/step - loss: 0.0027 - dice_coef: 0.9973 - val_loss: 0.0315 - val_dice_coef: 0.9685\n\nEpoch 00319: val_loss did not improve from 0.03090\nEpoch 320/400\n40/40 [==============================] - 4s 106ms/step - loss: 0.0027 - dice_coef: 0.9973 - val_loss: 0.0314 - val_dice_coef: 0.9686\n\nEpoch 00320: val_loss did not improve from 0.03090\nEpoch 321/400\n40/40 [==============================] - 4s 101ms/step - loss: 0.0028 - dice_coef: 0.9972 - val_loss: 0.0314 - val_dice_coef: 0.9686\n\nEpoch 00321: val_loss did not improve from 0.03090\nEpoch 322/400\n40/40 [==============================] - 4s 100ms/step - loss: 0.0028 - dice_coef: 0.9972 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00322: val_loss did not improve from 0.03090\nEpoch 323/400\n40/40 [==============================] - 4s 101ms/step - loss: 0.0028 - dice_coef: 0.9972 - val_loss: 0.0314 - val_dice_coef: 0.9686\n\nEpoch 00323: val_loss did not improve from 0.03090\nEpoch 324/400\n40/40 [==============================] - 5s 116ms/step - loss: 0.0029 - dice_coef: 0.9971 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00324: val_loss did not improve from 0.03090\nEpoch 325/400\n40/40 [==============================] - 4s 99ms/step - loss: 0.0029 - dice_coef: 0.9971 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00325: val_loss did not improve from 0.03090\nEpoch 326/400\n40/40 [==============================] - 4s 102ms/step - loss: 0.0028 - dice_coef: 0.9972 - val_loss: 0.0315 - val_dice_coef: 0.9685\n\nEpoch 00326: val_loss did not improve from 0.03090\nEpoch 327/400\n40/40 [==============================] - 4s 99ms/step - loss: 0.0029 - dice_coef: 0.9971 - val_loss: 0.0315 - val_dice_coef: 0.9685\n\nEpoch 00327: val_loss did not improve from 0.03090\nEpoch 328/400\n40/40 [==============================] - 4s 101ms/step - loss: 0.0029 - dice_coef: 0.9971 - val_loss: 0.0310 - val_dice_coef: 0.9690\n\nEpoch 00328: val_loss did not improve from 0.03090\nEpoch 329/400\n40/40 [==============================] - 4s 102ms/step - loss: 0.0030 - dice_coef: 0.9970 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00329: val_loss did not improve from 0.03090\nEpoch 330/400\n40/40 [==============================] - 4s 103ms/step - loss: 0.0029 - dice_coef: 0.9971 - val_loss: 0.0318 - val_dice_coef: 0.9682\n\nEpoch 00330: val_loss did not improve from 0.03090\nEpoch 331/400\n40/40 [==============================] - 4s 103ms/step - loss: 0.0029 - dice_coef: 0.9971 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00331: val_loss did not improve from 0.03090\nEpoch 332/400\n40/40 [==============================] - 4s 101ms/step - loss: 0.0029 - dice_coef: 0.9971 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00332: val_loss did not improve from 0.03090\nEpoch 333/400\n40/40 [==============================] - 4s 103ms/step - loss: 0.0029 - dice_coef: 0.9971 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00333: val_loss did not improve from 0.03090\nEpoch 334/400\n40/40 [==============================] - 4s 102ms/step - loss: 0.0029 - dice_coef: 0.9971 - val_loss: 0.0314 - val_dice_coef: 0.9686\n\nEpoch 00334: val_loss did not improve from 0.03090\nEpoch 335/400\n40/40 [==============================] - 4s 102ms/step - loss: 0.0030 - dice_coef: 0.9970 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00335: val_loss did not improve from 0.03090\nEpoch 336/400\n40/40 [==============================] - 4s 101ms/step - loss: 0.0029 - dice_coef: 0.9971 - val_loss: 0.0314 - val_dice_coef: 0.9686\n\nEpoch 00336: val_loss did not improve from 0.03090\nEpoch 337/400\n40/40 [==============================] - 4s 106ms/step - loss: 0.0029 - dice_coef: 0.9971 - val_loss: 0.0316 - val_dice_coef: 0.9684\n\nEpoch 00337: val_loss did not improve from 0.03090\nEpoch 338/400\n40/40 [==============================] - 4s 100ms/step - loss: 0.0030 - dice_coef: 0.9970 - val_loss: 0.0314 - val_dice_coef: 0.9686\n\nEpoch 00338: val_loss did not improve from 0.03090\nEpoch 339/400\n40/40 [==============================] - 4s 108ms/step - loss: 0.0029 - dice_coef: 0.9971 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00339: val_loss did not improve from 0.03090\nEpoch 340/400\n40/40 [==============================] - 4s 103ms/step - loss: 0.0029 - dice_coef: 0.9971 - val_loss: 0.0315 - val_dice_coef: 0.9685\n\nEpoch 00340: val_loss did not improve from 0.03090\nEpoch 341/400\n40/40 [==============================] - 4s 103ms/step - loss: 0.0029 - dice_coef: 0.9971 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00341: val_loss did not improve from 0.03090\nEpoch 342/400\n40/40 [==============================] - 4s 104ms/step - loss: 0.0029 - dice_coef: 0.9971 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00342: val_loss did not improve from 0.03090\nEpoch 343/400\n40/40 [==============================] - 4s 111ms/step - loss: 0.0028 - dice_coef: 0.9972 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00343: val_loss did not improve from 0.03090\nEpoch 344/400\n40/40 [==============================] - 4s 99ms/step - loss: 0.0029 - dice_coef: 0.9971 - val_loss: 0.0315 - val_dice_coef: 0.9685\n\nEpoch 00344: val_loss did not improve from 0.03090\nEpoch 345/400\n40/40 [==============================] - 4s 100ms/step - loss: 0.0029 - dice_coef: 0.9971 - val_loss: 0.0316 - val_dice_coef: 0.9684\n\nEpoch 00345: val_loss did not improve from 0.03090\nEpoch 346/400\n40/40 [==============================] - 4s 101ms/step - loss: 0.0029 - dice_coef: 0.9971 - val_loss: 0.0315 - val_dice_coef: 0.9685\n\nEpoch 00346: val_loss did not improve from 0.03090\nEpoch 347/400\n40/40 [==============================] - 4s 103ms/step - loss: 0.0028 - dice_coef: 0.9972 - val_loss: 0.0315 - val_dice_coef: 0.9685\n\nEpoch 00347: val_loss did not improve from 0.03090\nEpoch 348/400\n40/40 [==============================] - 4s 108ms/step - loss: 0.0028 - dice_coef: 0.9972 - val_loss: 0.0316 - val_dice_coef: 0.9684\n\nEpoch 00348: val_loss did not improve from 0.03090\nEpoch 349/400\n40/40 [==============================] - 4s 101ms/step - loss: 0.0028 - dice_coef: 0.9972 - val_loss: 0.0316 - val_dice_coef: 0.9684\n\nEpoch 00349: val_loss did not improve from 0.03090\nEpoch 350/400\n40/40 [==============================] - 4s 103ms/step - loss: 0.0028 - dice_coef: 0.9972 - val_loss: 0.0316 - val_dice_coef: 0.9684\n\nEpoch 00350: val_loss did not improve from 0.03090\nEpoch 351/400\n40/40 [==============================] - 4s 107ms/step - loss: 0.0028 - dice_coef: 0.9972 - val_loss: 0.0315 - val_dice_coef: 0.9685\n\nEpoch 00351: val_loss did not improve from 0.03090\nEpoch 352/400\n40/40 [==============================] - 4s 101ms/step - loss: 0.0028 - dice_coef: 0.9972 - val_loss: 0.0315 - val_dice_coef: 0.9685\n\nEpoch 00352: val_loss did not improve from 0.03090\nEpoch 353/400\n40/40 [==============================] - 4s 104ms/step - loss: 0.0028 - dice_coef: 0.9972 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00353: val_loss did not improve from 0.03090\nEpoch 354/400\n40/40 [==============================] - 4s 101ms/step - loss: 0.0028 - dice_coef: 0.9972 - val_loss: 0.0316 - val_dice_coef: 0.9684\n\nEpoch 00354: val_loss did not improve from 0.03090\nEpoch 355/400\n40/40 [==============================] - 4s 103ms/step - loss: 0.0028 - dice_coef: 0.9972 - val_loss: 0.0316 - val_dice_coef: 0.9684\n\nEpoch 00355: val_loss did not improve from 0.03090\nEpoch 356/400\n40/40 [==============================] - 4s 103ms/step - loss: 0.0029 - dice_coef: 0.9971 - val_loss: 0.0318 - val_dice_coef: 0.9682\n\nEpoch 00356: val_loss did not improve from 0.03090\nEpoch 357/400\n40/40 [==============================] - 4s 102ms/step - loss: 0.0029 - dice_coef: 0.9971 - val_loss: 0.0319 - val_dice_coef: 0.9681\n\nEpoch 00357: val_loss did not improve from 0.03090\nEpoch 358/400\n40/40 [==============================] - 4s 110ms/step - loss: 0.0029 - dice_coef: 0.9971 - val_loss: 0.0318 - val_dice_coef: 0.9682\n\nEpoch 00358: val_loss did not improve from 0.03090\nEpoch 359/400\n40/40 [==============================] - 4s 103ms/step - loss: 0.0029 - dice_coef: 0.9971 - val_loss: 0.0317 - val_dice_coef: 0.9683\n\nEpoch 00359: val_loss did not improve from 0.03090\nEpoch 360/400\n40/40 [==============================] - 4s 101ms/step - loss: 0.0029 - dice_coef: 0.9971 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00360: val_loss did not improve from 0.03090\nEpoch 361/400\n40/40 [==============================] - 4s 109ms/step - loss: 0.0029 - dice_coef: 0.9971 - val_loss: 0.0315 - val_dice_coef: 0.9685\n\nEpoch 00361: val_loss did not improve from 0.03090\nEpoch 362/400\n40/40 [==============================] - 4s 103ms/step - loss: 0.0029 - dice_coef: 0.9971 - val_loss: 0.0316 - val_dice_coef: 0.9684\n\nEpoch 00362: val_loss did not improve from 0.03090\nEpoch 363/400\n40/40 [==============================] - 4s 104ms/step - loss: 0.0029 - dice_coef: 0.9971 - val_loss: 0.0316 - val_dice_coef: 0.9684\n\nEpoch 00363: val_loss did not improve from 0.03090\nEpoch 364/400\n40/40 [==============================] - 5s 114ms/step - loss: 0.0029 - dice_coef: 0.9971 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00364: val_loss did not improve from 0.03090\nEpoch 365/400\n40/40 [==============================] - 4s 99ms/step - loss: 0.0028 - dice_coef: 0.9972 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00365: val_loss did not improve from 0.03090\nEpoch 366/400\n40/40 [==============================] - 4s 102ms/step - loss: 0.0028 - dice_coef: 0.9972 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00366: val_loss did not improve from 0.03090\nEpoch 367/400\n40/40 [==============================] - 4s 104ms/step - loss: 0.0028 - dice_coef: 0.9972 - val_loss: 0.0310 - val_dice_coef: 0.9690\n\nEpoch 00367: val_loss did not improve from 0.03090\nEpoch 368/400\n40/40 [==============================] - 4s 106ms/step - loss: 0.0028 - dice_coef: 0.9972 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00368: val_loss did not improve from 0.03090\nEpoch 369/400\n40/40 [==============================] - 4s 102ms/step - loss: 0.0030 - dice_coef: 0.9970 - val_loss: 0.0314 - val_dice_coef: 0.9686\n\nEpoch 00369: val_loss did not improve from 0.03090\nEpoch 370/400\n40/40 [==============================] - 4s 102ms/step - loss: 0.0031 - dice_coef: 0.9969 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00370: val_loss did not improve from 0.03090\nEpoch 371/400\n40/40 [==============================] - 4s 103ms/step - loss: 0.0032 - dice_coef: 0.9968 - val_loss: 0.0314 - val_dice_coef: 0.9686\n\nEpoch 00371: val_loss did not improve from 0.03090\nEpoch 372/400\n40/40 [==============================] - 4s 103ms/step - loss: 0.0030 - dice_coef: 0.9970 - val_loss: 0.0318 - val_dice_coef: 0.9682\n\nEpoch 00372: val_loss did not improve from 0.03090\nEpoch 373/400\n40/40 [==============================] - 4s 103ms/step - loss: 0.0031 - dice_coef: 0.9969 - val_loss: 0.0316 - val_dice_coef: 0.9684\n\nEpoch 00373: val_loss did not improve from 0.03090\nEpoch 374/400\n40/40 [==============================] - 4s 101ms/step - loss: 0.0031 - dice_coef: 0.9969 - val_loss: 0.0316 - val_dice_coef: 0.9684\n\nEpoch 00374: val_loss did not improve from 0.03090\nEpoch 375/400\n40/40 [==============================] - 4s 112ms/step - loss: 0.0032 - dice_coef: 0.9968 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00375: val_loss did not improve from 0.03090\nEpoch 376/400\n40/40 [==============================] - 4s 103ms/step - loss: 0.0032 - dice_coef: 0.9968 - val_loss: 0.0319 - val_dice_coef: 0.9681\n\nEpoch 00376: val_loss did not improve from 0.03090\nEpoch 377/400\n40/40 [==============================] - 4s 103ms/step - loss: 0.0030 - dice_coef: 0.9970 - val_loss: 0.0322 - val_dice_coef: 0.9678\n\nEpoch 00377: val_loss did not improve from 0.03090\nEpoch 378/400\n40/40 [==============================] - 4s 103ms/step - loss: 0.0033 - dice_coef: 0.9967 - val_loss: 0.0316 - val_dice_coef: 0.9684\n\nEpoch 00378: val_loss did not improve from 0.03090\nEpoch 379/400\n40/40 [==============================] - 4s 104ms/step - loss: 0.0032 - dice_coef: 0.9968 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00379: val_loss did not improve from 0.03090\nEpoch 380/400\n40/40 [==============================] - 4s 103ms/step - loss: 0.0034 - dice_coef: 0.9966 - val_loss: 0.0317 - val_dice_coef: 0.9683\n\nEpoch 00380: val_loss did not improve from 0.03090\nEpoch 381/400\n40/40 [==============================] - 4s 108ms/step - loss: 0.0033 - dice_coef: 0.9967 - val_loss: 0.0317 - val_dice_coef: 0.9683\n\nEpoch 00381: val_loss did not improve from 0.03090\nEpoch 382/400\n40/40 [==============================] - 4s 101ms/step - loss: 0.0032 - dice_coef: 0.9968 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00382: val_loss did not improve from 0.03090\nEpoch 383/400\n40/40 [==============================] - 4s 105ms/step - loss: 0.0031 - dice_coef: 0.9969 - val_loss: 0.0318 - val_dice_coef: 0.9682\n\nEpoch 00383: val_loss did not improve from 0.03090\nEpoch 384/400\n40/40 [==============================] - 4s 102ms/step - loss: 0.0032 - dice_coef: 0.9968 - val_loss: 0.0320 - val_dice_coef: 0.9680\n\nEpoch 00384: val_loss did not improve from 0.03090\nEpoch 385/400\n40/40 [==============================] - 4s 103ms/step - loss: 0.0032 - dice_coef: 0.9968 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00385: val_loss did not improve from 0.03090\nEpoch 386/400\n40/40 [==============================] - 4s 102ms/step - loss: 0.0032 - dice_coef: 0.9968 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00386: val_loss did not improve from 0.03090\nEpoch 387/400\n40/40 [==============================] - 5s 116ms/step - loss: 0.0033 - dice_coef: 0.9967 - val_loss: 0.0317 - val_dice_coef: 0.9683\n\nEpoch 00387: val_loss did not improve from 0.03090\nEpoch 388/400\n40/40 [==============================] - 5s 113ms/step - loss: 0.0033 - dice_coef: 0.9967 - val_loss: 0.0318 - val_dice_coef: 0.9682\n\nEpoch 00388: val_loss did not improve from 0.03090\nEpoch 389/400\n40/40 [==============================] - 4s 100ms/step - loss: 0.0034 - dice_coef: 0.9966 - val_loss: 0.0317 - val_dice_coef: 0.9683\n\nEpoch 00389: val_loss did not improve from 0.03090\nEpoch 390/400\n40/40 [==============================] - 4s 102ms/step - loss: 0.0033 - dice_coef: 0.9967 - val_loss: 0.0317 - val_dice_coef: 0.9683\n\nEpoch 00390: val_loss did not improve from 0.03090\nEpoch 391/400\n40/40 [==============================] - 4s 102ms/step - loss: 0.0035 - dice_coef: 0.9965 - val_loss: 0.0321 - val_dice_coef: 0.9679\n\nEpoch 00391: val_loss did not improve from 0.03090\nEpoch 392/400\n40/40 [==============================] - 4s 105ms/step - loss: 0.0034 - dice_coef: 0.9966 - val_loss: 0.0315 - val_dice_coef: 0.9685\n\nEpoch 00392: val_loss did not improve from 0.03090\nEpoch 393/400\n40/40 [==============================] - 4s 103ms/step - loss: 0.0033 - dice_coef: 0.9967 - val_loss: 0.0325 - val_dice_coef: 0.9675\n\nEpoch 00393: val_loss did not improve from 0.03090\nEpoch 394/400\n40/40 [==============================] - 4s 102ms/step - loss: 0.0035 - dice_coef: 0.9965 - val_loss: 0.0315 - val_dice_coef: 0.9685\n\nEpoch 00394: val_loss did not improve from 0.03090\nEpoch 395/400\n40/40 [==============================] - 4s 107ms/step - loss: 0.0032 - dice_coef: 0.9968 - val_loss: 0.0315 - val_dice_coef: 0.9685\n\nEpoch 00395: val_loss did not improve from 0.03090\nEpoch 396/400\n40/40 [==============================] - 4s 104ms/step - loss: 0.0034 - dice_coef: 0.9966 - val_loss: 0.0318 - val_dice_coef: 0.9682\n\nEpoch 00396: val_loss did not improve from 0.03090\nEpoch 397/400\n40/40 [==============================] - 5s 117ms/step - loss: 0.0033 - dice_coef: 0.9967 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00397: val_loss did not improve from 0.03090\nEpoch 398/400\n40/40 [==============================] - 4s 101ms/step - loss: 0.0031 - dice_coef: 0.9969 - val_loss: 0.0323 - val_dice_coef: 0.9677\n\nEpoch 00398: val_loss did not improve from 0.03090\nEpoch 399/400\n40/40 [==============================] - 4s 102ms/step - loss: 0.0032 - dice_coef: 0.9968 - val_loss: 0.0320 - val_dice_coef: 0.9680\n\nEpoch 00399: val_loss did not improve from 0.03090\nEpoch 400/400\n40/40 [==============================] - 4s 100ms/step - loss: 0.0031 - dice_coef: 0.9969 - val_loss: 0.0317 - val_dice_coef: 0.9683\n\nEpoch 00400: val_loss did not improve from 0.03090\n"
    }
   ],
   "source": [
    "train_history_f1 = unet_f1.fit(x = train_x, y = train_y, validation_data = (test_x, test_y), callbacks= call_back,\n",
    "                              batch_size= 10, epochs= 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del(unet_f1)\n",
    "#del(history)\n",
    "#del(call_back)\n",
    "#del(train_history_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Floder2 (train : f01, f03 , test : f02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = floder2[0], floder2[1], floder2[2], floder2[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "preprocessing....\n\ndealing with image....\n\npreprocessing for image finish!\n\ndealing with label....\n\nlabel_to_class_label finish!\n\nFunction label_to_1Hlabel finish!\n\npreprocessing for label finish!\n\n"
    }
   ],
   "source": [
    "train_x, train_y = datapreprocessing(train_x, train_y, resize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "preprocessing....\n\ndealing with image....\n\npreprocessing for image finish!\n\ndealing with label....\n\nlabel_to_class_label finish!\n\nFunction label_to_1Hlabel finish!\n\npreprocessing for label finish!\n\n"
    }
   ],
   "source": [
    "test_x, test_y = datapreprocessing(test_x, test_y, resize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Function transfer_to_train_data finish!\n\n"
    }
   ],
   "source": [
    "train_x = transfer_to_train_data(train_x, (train_x.shape[0], train_x.shape[1],train_x.shape[2],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Function transfer_to_train_data finish!\n\n"
    }
   ],
   "source": [
    "test_x = transfer_to_train_data(test_x, (test_x.shape[0], test_x.shape[1],test_x.shape[2],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = History()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_back = [checkpoint, history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput (InputLayer)              (None, 672, 224, 1)  0                                            \n__________________________________________________________________________________________________\nc_1_conv1 (Conv2D)              (None, 672, 224, 16) 1312        input[0][0]                      \n__________________________________________________________________________________________________\nc_1_BN1 (BatchNormalization)    (None, 672, 224, 16) 64          c_1_conv1[0][0]                  \n__________________________________________________________________________________________________\nc_1_conv2 (Conv2D)              (None, 672, 224, 16) 20752       c_1_BN1[0][0]                    \n__________________________________________________________________________________________________\nc_1_BN2 (BatchNormalization)    (None, 672, 224, 16) 64          c_1_conv2[0][0]                  \n__________________________________________________________________________________________________\nc_1_maxpool1 (MaxPooling2D)     (None, 336, 112, 16) 0           c_1_BN2[0][0]                    \n__________________________________________________________________________________________________\nc_2_conv1 (Conv2D)              (None, 336, 112, 32) 41504       c_1_maxpool1[0][0]               \n__________________________________________________________________________________________________\nc_2_BN1 (BatchNormalization)    (None, 336, 112, 32) 128         c_2_conv1[0][0]                  \n__________________________________________________________________________________________________\nc_2_conv2 (Conv2D)              (None, 336, 112, 32) 82976       c_2_BN1[0][0]                    \n__________________________________________________________________________________________________\nc_2_BN2 (BatchNormalization)    (None, 336, 112, 32) 128         c_2_conv2[0][0]                  \n__________________________________________________________________________________________________\nc_2_maxpool1 (MaxPooling2D)     (None, 168, 56, 32)  0           c_2_BN2[0][0]                    \n__________________________________________________________________________________________________\nc_3_conv1 (Conv2D)              (None, 168, 56, 64)  165952      c_2_maxpool1[0][0]               \n__________________________________________________________________________________________________\nc_3_BN1 (BatchNormalization)    (None, 168, 56, 64)  256         c_3_conv1[0][0]                  \n__________________________________________________________________________________________________\nc_3_conv2 (Conv2D)              (None, 168, 56, 64)  331840      c_3_BN1[0][0]                    \n__________________________________________________________________________________________________\nc_3_BN2 (BatchNormalization)    (None, 168, 56, 64)  256         c_3_conv2[0][0]                  \n__________________________________________________________________________________________________\nc_3_maxpool1 (MaxPooling2D)     (None, 84, 28, 64)   0           c_3_BN2[0][0]                    \n__________________________________________________________________________________________________\nc_4_conv1 (Conv2D)              (None, 84, 28, 128)  663680      c_3_maxpool1[0][0]               \n__________________________________________________________________________________________________\nc_4_BN1 (BatchNormalization)    (None, 84, 28, 128)  512         c_4_conv1[0][0]                  \n__________________________________________________________________________________________________\nc_4_conv2 (Conv2D)              (None, 84, 28, 128)  1327232     c_4_BN1[0][0]                    \n__________________________________________________________________________________________________\nc_4_BN2 (BatchNormalization)    (None, 84, 28, 128)  512         c_4_conv2[0][0]                  \n__________________________________________________________________________________________________\nc_4_maxpool1 (MaxPooling2D)     (None, 42, 14, 128)  0           c_4_BN2[0][0]                    \n__________________________________________________________________________________________________\nb_conv1 (Conv2D)                (None, 42, 14, 256)  2654464     c_4_maxpool1[0][0]               \n__________________________________________________________________________________________________\nb_BN1 (BatchNormalization)      (None, 42, 14, 256)  1024        b_conv1[0][0]                    \n__________________________________________________________________________________________________\nb_conv2 (Conv2D)                (None, 42, 14, 256)  5308672     b_BN1[0][0]                      \n__________________________________________________________________________________________________\nb_BN2 (BatchNormalization)      (None, 42, 14, 256)  1024        b_conv2[0][0]                    \n__________________________________________________________________________________________________\ne_1_Tconv (Conv2DTranspose)     (None, 84, 28, 128)  2654336     b_BN2[0][0]                      \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 84, 28, 256)  0           c_4_BN2[0][0]                    \n                                                                 e_1_Tconv[0][0]                  \n__________________________________________________________________________________________________\ne_1_conv1 (Conv2D)              (None, 84, 28, 128)  2654336     concatenate[0][0]                \n__________________________________________________________________________________________________\ne_1_BN1 (BatchNormalization)    (None, 84, 28, 128)  512         e_1_conv1[0][0]                  \n__________________________________________________________________________________________________\ne_1_conv2 (Conv2D)              (None, 84, 28, 128)  1327232     e_1_BN1[0][0]                    \n__________________________________________________________________________________________________\ne_1_BN2 (BatchNormalization)    (None, 84, 28, 128)  512         e_1_conv2[0][0]                  \n__________________________________________________________________________________________________\ne_2_Tconv (Conv2DTranspose)     (None, 168, 56, 64)  663616      e_1_BN2[0][0]                    \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 168, 56, 128) 0           c_3_BN2[0][0]                    \n                                                                 e_2_Tconv[0][0]                  \n__________________________________________________________________________________________________\ne_2_conv1 (Conv2D)              (None, 168, 56, 64)  663616      concatenate_1[0][0]              \n__________________________________________________________________________________________________\ne_2_BN1 (BatchNormalization)    (None, 168, 56, 64)  256         e_2_conv1[0][0]                  \n__________________________________________________________________________________________________\ne_2_conv2 (Conv2D)              (None, 168, 56, 64)  331840      e_2_BN1[0][0]                    \n__________________________________________________________________________________________________\ne_2_BN2 (BatchNormalization)    (None, 168, 56, 64)  256         e_2_conv2[0][0]                  \n__________________________________________________________________________________________________\ne_3_Tconv (Conv2DTranspose)     (None, 336, 112, 32) 165920      e_2_BN2[0][0]                    \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 336, 112, 64) 0           c_2_BN2[0][0]                    \n                                                                 e_3_Tconv[0][0]                  \n__________________________________________________________________________________________________\ne_3_conv1 (Conv2D)              (None, 336, 112, 32) 165920      concatenate_2[0][0]              \n__________________________________________________________________________________________________\ne_3_BN1 (BatchNormalization)    (None, 336, 112, 32) 128         e_3_conv1[0][0]                  \n__________________________________________________________________________________________________\ne_3_conv2 (Conv2D)              (None, 336, 112, 32) 82976       e_3_BN1[0][0]                    \n__________________________________________________________________________________________________\ne_3_BN2 (BatchNormalization)    (None, 336, 112, 32) 128         e_3_conv2[0][0]                  \n__________________________________________________________________________________________________\ne_4_Tconv (Conv2DTranspose)     (None, 672, 224, 16) 41488       e_3_BN2[0][0]                    \n__________________________________________________________________________________________________\nconcatenate_3 (Concatenate)     (None, 672, 224, 32) 0           c_1_BN2[0][0]                    \n                                                                 e_4_Tconv[0][0]                  \n__________________________________________________________________________________________________\ne_4_conv1 (Conv2D)              (None, 672, 224, 16) 41488       concatenate_3[0][0]              \n__________________________________________________________________________________________________\ne_4_BN1 (BatchNormalization)    (None, 672, 224, 16) 64          e_4_conv1[0][0]                  \n__________________________________________________________________________________________________\ne_4_conv2 (Conv2D)              (None, 672, 224, 16) 20752       e_4_BN1[0][0]                    \n__________________________________________________________________________________________________\ne_4_BN2 (BatchNormalization)    (None, 672, 224, 16) 64          e_4_conv2[0][0]                  \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 672, 224, 2)  34          e_4_BN2[0][0]                    \n==================================================================================================\nTotal params: 19,417,826\nTrainable params: 19,414,882\nNon-trainable params: 2,944\n__________________________________________________________________________________________________\nNone\n"
    }
   ],
   "source": [
    "unet_f2 = u_net((672,224,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0 [==============================] - 4s 106ms/step - loss: 0.0038 - dice_coef: 0.9962 - val_loss: 0.0296 - val_dice_coef: 0.9704\n\nEpoch 00902: val_loss did not improve from 0.02903\nEpoch 903/1000\n40/40 [==============================] - 4s 102ms/step - loss: 0.0038 - dice_coef: 0.9962 - val_loss: 0.0294 - val_dice_coef: 0.9706\n\nEpoch 00903: val_loss did not improve from 0.02903\nEpoch 904/1000\n40/40 [==============================] - 4s 101ms/step - loss: 0.0038 - dice_coef: 0.9962 - val_loss: 0.0291 - val_dice_coef: 0.9709\n\nEpoch 00904: val_loss did not improve from 0.02903\nEpoch 905/1000\n40/40 [==============================] - 4s 104ms/step - loss: 0.0038 - dice_coef: 0.9962 - val_loss: 0.0293 - val_dice_coef: 0.9707\n\nEpoch 00905: val_loss did not improve from 0.02903\nEpoch 906/1000\n40/40 [==============================] - 4s 99ms/step - loss: 0.0038 - dice_coef: 0.9962 - val_loss: 0.0292 - val_dice_coef: 0.9708\n\nEpoch 00906: val_loss did not improve from 0.02903\nEpoch 907/1000\n40/40 [==============================] - 4s 102ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0291 - val_dice_coef: 0.9709\n\nEpoch 00907: val_loss did not improve from 0.02903\nEpoch 908/1000\n40/40 [==============================] - 4s 101ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0294 - val_dice_coef: 0.9706\n\nEpoch 00908: val_loss did not improve from 0.02903\nEpoch 909/1000\n40/40 [==============================] - 4s 102ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0294 - val_dice_coef: 0.9706\n\nEpoch 00909: val_loss did not improve from 0.02903\nEpoch 910/1000\n40/40 [==============================] - 4s 108ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0293 - val_dice_coef: 0.9707\n\nEpoch 00910: val_loss did not improve from 0.02903\nEpoch 911/1000\n40/40 [==============================] - 4s 100ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0292 - val_dice_coef: 0.9708\n\nEpoch 00911: val_loss did not improve from 0.02903\nEpoch 912/1000\n40/40 [==============================] - 4s 102ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0291 - val_dice_coef: 0.9709\n\nEpoch 00912: val_loss did not improve from 0.02903\nEpoch 913/1000\n40/40 [==============================] - 4s 102ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0291 - val_dice_coef: 0.9709\n\nEpoch 00913: val_loss did not improve from 0.02903\nEpoch 914/1000\n40/40 [==============================] - 4s 107ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0293 - val_dice_coef: 0.9707\n\nEpoch 00914: val_loss did not improve from 0.02903\nEpoch 915/1000\n40/40 [==============================] - 4s 102ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0293 - val_dice_coef: 0.9707\n\nEpoch 00915: val_loss did not improve from 0.02903\nEpoch 916/1000\n40/40 [==============================] - 4s 100ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0293 - val_dice_coef: 0.9707\n\nEpoch 00916: val_loss did not improve from 0.02903\nEpoch 917/1000\n40/40 [==============================] - 4s 104ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0296 - val_dice_coef: 0.9704\n\nEpoch 00917: val_loss did not improve from 0.02903\nEpoch 918/1000\n40/40 [==============================] - 4s 101ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0291 - val_dice_coef: 0.9709\n\nEpoch 00918: val_loss did not improve from 0.02903\nEpoch 919/1000\n40/40 [==============================] - 4s 101ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0291 - val_dice_coef: 0.9709\n\nEpoch 00919: val_loss did not improve from 0.02903\nEpoch 920/1000\n40/40 [==============================] - 4s 112ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0295 - val_dice_coef: 0.9705\n\nEpoch 00920: val_loss did not improve from 0.02903\nEpoch 921/1000\n40/40 [==============================] - 4s 99ms/step - loss: 0.0038 - dice_coef: 0.9962 - val_loss: 0.0292 - val_dice_coef: 0.9708\n\nEpoch 00921: val_loss did not improve from 0.02903\nEpoch 922/1000\n40/40 [==============================] - 4s 106ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0292 - val_dice_coef: 0.9708\n\nEpoch 00922: val_loss did not improve from 0.02903\nEpoch 923/1000\n40/40 [==============================] - 4s 100ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0293 - val_dice_coef: 0.9707\n\nEpoch 00923: val_loss did not improve from 0.02903\nEpoch 924/1000\n40/40 [==============================] - 4s 102ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0293 - val_dice_coef: 0.9707\n\nEpoch 00924: val_loss did not improve from 0.02903\nEpoch 925/1000\n40/40 [==============================] - 4s 110ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0292 - val_dice_coef: 0.9708\n\nEpoch 00925: val_loss did not improve from 0.02903\nEpoch 926/1000\n40/40 [==============================] - 4s 98ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0291 - val_dice_coef: 0.9709\n\nEpoch 00926: val_loss did not improve from 0.02903\nEpoch 927/1000\n40/40 [==============================] - 4s 105ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0291 - val_dice_coef: 0.9709\n\nEpoch 00927: val_loss did not improve from 0.02903\nEpoch 928/1000\n40/40 [==============================] - 4s 107ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0292 - val_dice_coef: 0.9708\n\nEpoch 00928: val_loss did not improve from 0.02903\nEpoch 929/1000\n40/40 [==============================] - 4s 100ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0292 - val_dice_coef: 0.9708\n\nEpoch 00929: val_loss did not improve from 0.02903\nEpoch 930/1000\n40/40 [==============================] - 4s 103ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0293 - val_dice_coef: 0.9707\n\nEpoch 00930: val_loss did not improve from 0.02903\nEpoch 931/1000\n40/40 [==============================] - 4s 100ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0293 - val_dice_coef: 0.9707\n\nEpoch 00931: val_loss did not improve from 0.02903\nEpoch 932/1000\n40/40 [==============================] - 4s 103ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0293 - val_dice_coef: 0.9707\n\nEpoch 00932: val_loss did not improve from 0.02903\nEpoch 933/1000\n40/40 [==============================] - 4s 102ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0292 - val_dice_coef: 0.9708\n\nEpoch 00933: val_loss did not improve from 0.02903\nEpoch 934/1000\n40/40 [==============================] - 4s 99ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0293 - val_dice_coef: 0.9707\n\nEpoch 00934: val_loss did not improve from 0.02903\nEpoch 935/1000\n40/40 [==============================] - 4s 104ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0292 - val_dice_coef: 0.9708\n\nEpoch 00935: val_loss did not improve from 0.02903\nEpoch 936/1000\n40/40 [==============================] - 4s 101ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0294 - val_dice_coef: 0.9706\n\nEpoch 00936: val_loss did not improve from 0.02903\nEpoch 937/1000\n40/40 [==============================] - 4s 105ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0291 - val_dice_coef: 0.9709\n\nEpoch 00937: val_loss did not improve from 0.02903\nEpoch 938/1000\n40/40 [==============================] - 4s 102ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0292 - val_dice_coef: 0.9708\n\nEpoch 00938: val_loss did not improve from 0.02903\nEpoch 939/1000\n40/40 [==============================] - 4s 104ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0290 - val_dice_coef: 0.9710\n\nEpoch 00939: val_loss did not improve from 0.02903\nEpoch 940/1000\n40/40 [==============================] - 4s 102ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0289 - val_dice_coef: 0.9711\n\nEpoch 00940: val_loss improved from 0.02903 to 0.02893, saving model to best_pretrain_weights.h5\nEpoch 941/1000\n40/40 [==============================] - 4s 101ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0290 - val_dice_coef: 0.9710\n\nEpoch 00941: val_loss did not improve from 0.02893\nEpoch 942/1000\n40/40 [==============================] - 4s 101ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0289 - val_dice_coef: 0.9711\n\nEpoch 00942: val_loss improved from 0.02893 to 0.02889, saving model to best_pretrain_weights.h5\nEpoch 943/1000\n40/40 [==============================] - 4s 98ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0291 - val_dice_coef: 0.9709\n\nEpoch 00943: val_loss did not improve from 0.02889\nEpoch 944/1000\n40/40 [==============================] - 4s 101ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0293 - val_dice_coef: 0.9707\n\nEpoch 00944: val_loss did not improve from 0.02889\nEpoch 945/1000\n40/40 [==============================] - 4s 101ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0295 - val_dice_coef: 0.9705\n\nEpoch 00945: val_loss did not improve from 0.02889\nEpoch 946/1000\n40/40 [==============================] - 4s 109ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0294 - val_dice_coef: 0.9706\n\nEpoch 00946: val_loss did not improve from 0.02889\nEpoch 947/1000\n40/40 [==============================] - 4s 101ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0293 - val_dice_coef: 0.9707\n\nEpoch 00947: val_loss did not improve from 0.02889\nEpoch 948/1000\n40/40 [==============================] - 4s 112ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0293 - val_dice_coef: 0.9707\n\nEpoch 00948: val_loss did not improve from 0.02889\nEpoch 949/1000\n40/40 [==============================] - 4s 97ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0293 - val_dice_coef: 0.9707\n\nEpoch 00949: val_loss did not improve from 0.02889\nEpoch 950/1000\n40/40 [==============================] - 4s 106ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0297 - val_dice_coef: 0.9703\n\nEpoch 00950: val_loss did not improve from 0.02889\nEpoch 951/1000\n40/40 [==============================] - 4s 108ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0290 - val_dice_coef: 0.9710\n\nEpoch 00951: val_loss did not improve from 0.02889\nEpoch 952/1000\n40/40 [==============================] - 4s 103ms/step - loss: 0.0038 - dice_coef: 0.9962 - val_loss: 0.0294 - val_dice_coef: 0.9706\n\nEpoch 00952: val_loss did not improve from 0.02889\nEpoch 953/1000\n40/40 [==============================] - 4s 101ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0291 - val_dice_coef: 0.9709\n\nEpoch 00953: val_loss did not improve from 0.02889\nEpoch 954/1000\n40/40 [==============================] - 4s 102ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0293 - val_dice_coef: 0.9707\n\nEpoch 00954: val_loss did not improve from 0.02889\nEpoch 955/1000\n40/40 [==============================] - 4s 108ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0291 - val_dice_coef: 0.9709\n\nEpoch 00955: val_loss did not improve from 0.02889\nEpoch 956/1000\n40/40 [==============================] - 4s 102ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0290 - val_dice_coef: 0.9710\n\nEpoch 00956: val_loss did not improve from 0.02889\nEpoch 957/1000\n40/40 [==============================] - 4s 100ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0293 - val_dice_coef: 0.9707\n\nEpoch 00957: val_loss did not improve from 0.02889\nEpoch 958/1000\n40/40 [==============================] - 4s 105ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0291 - val_dice_coef: 0.9709\n\nEpoch 00958: val_loss did not improve from 0.02889\nEpoch 959/1000\n40/40 [==============================] - 4s 98ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0292 - val_dice_coef: 0.9708\n\nEpoch 00959: val_loss did not improve from 0.02889\nEpoch 960/1000\n40/40 [==============================] - 4s 103ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0291 - val_dice_coef: 0.9709\n\nEpoch 00960: val_loss did not improve from 0.02889\nEpoch 961/1000\n40/40 [==============================] - 4s 109ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0289 - val_dice_coef: 0.9711\n\nEpoch 00961: val_loss did not improve from 0.02889\nEpoch 962/1000\n40/40 [==============================] - 4s 100ms/step - loss: 0.0035 - dice_coef: 0.9965 - val_loss: 0.0293 - val_dice_coef: 0.9707\n\nEpoch 00962: val_loss did not improve from 0.02889\nEpoch 963/1000\n40/40 [==============================] - 4s 101ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0291 - val_dice_coef: 0.9709\n\nEpoch 00963: val_loss did not improve from 0.02889\nEpoch 964/1000\n40/40 [==============================] - 4s 103ms/step - loss: 0.0035 - dice_coef: 0.9965 - val_loss: 0.0292 - val_dice_coef: 0.9708\n\nEpoch 00964: val_loss did not improve from 0.02889\nEpoch 965/1000\n40/40 [==============================] - 4s 104ms/step - loss: 0.0035 - dice_coef: 0.9965 - val_loss: 0.0293 - val_dice_coef: 0.9707\n\nEpoch 00965: val_loss did not improve from 0.02889\nEpoch 966/1000\n40/40 [==============================] - 4s 106ms/step - loss: 0.0035 - dice_coef: 0.9965 - val_loss: 0.0291 - val_dice_coef: 0.9709\n\nEpoch 00966: val_loss did not improve from 0.02889\nEpoch 967/1000\n40/40 [==============================] - 4s 99ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0293 - val_dice_coef: 0.9707\n\nEpoch 00967: val_loss did not improve from 0.02889\nEpoch 968/1000\n40/40 [==============================] - 4s 107ms/step - loss: 0.0035 - dice_coef: 0.9965 - val_loss: 0.0293 - val_dice_coef: 0.9707\n\nEpoch 00968: val_loss did not improve from 0.02889\nEpoch 969/1000\n40/40 [==============================] - 4s 98ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0290 - val_dice_coef: 0.9710\n\nEpoch 00969: val_loss did not improve from 0.02889\nEpoch 970/1000\n40/40 [==============================] - 4s 104ms/step - loss: 0.0035 - dice_coef: 0.9965 - val_loss: 0.0294 - val_dice_coef: 0.9706\n\nEpoch 00970: val_loss did not improve from 0.02889\nEpoch 971/1000\n40/40 [==============================] - 4s 100ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0289 - val_dice_coef: 0.9711\n\nEpoch 00971: val_loss did not improve from 0.02889\nEpoch 972/1000\n40/40 [==============================] - 4s 103ms/step - loss: 0.0035 - dice_coef: 0.9965 - val_loss: 0.0291 - val_dice_coef: 0.9709\n\nEpoch 00972: val_loss did not improve from 0.02889\nEpoch 973/1000\n40/40 [==============================] - 4s 102ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0293 - val_dice_coef: 0.9707\n\nEpoch 00973: val_loss did not improve from 0.02889\nEpoch 974/1000\n40/40 [==============================] - 4s 103ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0290 - val_dice_coef: 0.9710\n\nEpoch 00974: val_loss did not improve from 0.02889\nEpoch 975/1000\n40/40 [==============================] - 4s 103ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0291 - val_dice_coef: 0.9709\n\nEpoch 00975: val_loss did not improve from 0.02889\nEpoch 976/1000\n40/40 [==============================] - 4s 101ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0289 - val_dice_coef: 0.9711\n\nEpoch 00976: val_loss did not improve from 0.02889\nEpoch 977/1000\n40/40 [==============================] - 4s 109ms/step - loss: 0.0040 - dice_coef: 0.9960 - val_loss: 0.0289 - val_dice_coef: 0.9711\n\nEpoch 00977: val_loss improved from 0.02889 to 0.02889, saving model to best_pretrain_weights.h5\nEpoch 978/1000\n40/40 [==============================] - 4s 96ms/step - loss: 0.0040 - dice_coef: 0.9960 - val_loss: 0.0290 - val_dice_coef: 0.9710\n\nEpoch 00978: val_loss did not improve from 0.02889\nEpoch 979/1000\n40/40 [==============================] - 4s 101ms/step - loss: 0.0039 - dice_coef: 0.9961 - val_loss: 0.0288 - val_dice_coef: 0.9712\n\nEpoch 00979: val_loss improved from 0.02889 to 0.02877, saving model to best_pretrain_weights.h5\nEpoch 980/1000\n40/40 [==============================] - 4s 98ms/step - loss: 0.0038 - dice_coef: 0.9962 - val_loss: 0.0289 - val_dice_coef: 0.9711\n\nEpoch 00980: val_loss did not improve from 0.02877\nEpoch 981/1000\n40/40 [==============================] - 4s 98ms/step - loss: 0.0038 - dice_coef: 0.9962 - val_loss: 0.0290 - val_dice_coef: 0.9710\n\nEpoch 00981: val_loss did not improve from 0.02877\nEpoch 982/1000\n40/40 [==============================] - 4s 104ms/step - loss: 0.0038 - dice_coef: 0.9962 - val_loss: 0.0290 - val_dice_coef: 0.9710\n\nEpoch 00982: val_loss did not improve from 0.02877\nEpoch 983/1000\n40/40 [==============================] - 4s 104ms/step - loss: 0.0038 - dice_coef: 0.9962 - val_loss: 0.0293 - val_dice_coef: 0.9707\n\nEpoch 00983: val_loss did not improve from 0.02877\nEpoch 984/1000\n40/40 [==============================] - 4s 103ms/step - loss: 0.0039 - dice_coef: 0.9961 - val_loss: 0.0290 - val_dice_coef: 0.9710\n\nEpoch 00984: val_loss did not improve from 0.02877\nEpoch 985/1000\n40/40 [==============================] - 4s 112ms/step - loss: 0.0039 - dice_coef: 0.9961 - val_loss: 0.0290 - val_dice_coef: 0.9710\n\nEpoch 00985: val_loss did not improve from 0.02877\nEpoch 986/1000\n40/40 [==============================] - 4s 100ms/step - loss: 0.0039 - dice_coef: 0.9961 - val_loss: 0.0289 - val_dice_coef: 0.9711\n\nEpoch 00986: val_loss did not improve from 0.02877\nEpoch 987/1000\n40/40 [==============================] - 4s 100ms/step - loss: 0.0039 - dice_coef: 0.9961 - val_loss: 0.0292 - val_dice_coef: 0.9708\n\nEpoch 00987: val_loss did not improve from 0.02877\nEpoch 988/1000\n40/40 [==============================] - 4s 101ms/step - loss: 0.0038 - dice_coef: 0.9962 - val_loss: 0.0293 - val_dice_coef: 0.9707\n\nEpoch 00988: val_loss did not improve from 0.02877\nEpoch 989/1000\n40/40 [==============================] - 4s 106ms/step - loss: 0.0038 - dice_coef: 0.9962 - val_loss: 0.0291 - val_dice_coef: 0.9709\n\nEpoch 00989: val_loss did not improve from 0.02877\nEpoch 990/1000\n40/40 [==============================] - 4s 109ms/step - loss: 0.0038 - dice_coef: 0.9962 - val_loss: 0.0292 - val_dice_coef: 0.9708\n\nEpoch 00990: val_loss did not improve from 0.02877\nEpoch 991/1000\n40/40 [==============================] - 4s 103ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0290 - val_dice_coef: 0.9710\n\nEpoch 00991: val_loss did not improve from 0.02877\nEpoch 992/1000\n40/40 [==============================] - 4s 100ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0289 - val_dice_coef: 0.9711\n\nEpoch 00992: val_loss did not improve from 0.02877\nEpoch 993/1000\n40/40 [==============================] - 4s 105ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0290 - val_dice_coef: 0.9710\n\nEpoch 00993: val_loss did not improve from 0.02877\nEpoch 994/1000\n40/40 [==============================] - 4s 101ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0295 - val_dice_coef: 0.9705\n\nEpoch 00994: val_loss did not improve from 0.02877\nEpoch 995/1000\n40/40 [==============================] - 4s 109ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0295 - val_dice_coef: 0.9705\n\nEpoch 00995: val_loss did not improve from 0.02877\nEpoch 996/1000\n40/40 [==============================] - 4s 100ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0287 - val_dice_coef: 0.9713\n\nEpoch 00996: val_loss improved from 0.02877 to 0.02873, saving model to best_pretrain_weights.h5\nEpoch 997/1000\n40/40 [==============================] - 4s 105ms/step - loss: 0.0038 - dice_coef: 0.9962 - val_loss: 0.0290 - val_dice_coef: 0.9710\n\nEpoch 00997: val_loss did not improve from 0.02873\nEpoch 998/1000\n40/40 [==============================] - 4s 104ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0292 - val_dice_coef: 0.9708\n\nEpoch 00998: val_loss did not improve from 0.02873\nEpoch 999/1000\n40/40 [==============================] - 4s 101ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0292 - val_dice_coef: 0.9708\n\nEpoch 00999: val_loss did not improve from 0.02873\nEpoch 1000/1000\n40/40 [==============================] - 4s 104ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0294 - val_dice_coef: 0.9706\n\nEpoch 01000: val_loss did not improve from 0.02873\n"
    }
   ],
   "source": [
    "train_history_f2 = unet_f2.fit(x = train_x, y = train_y, validation_data = (test_x, test_y), callbacks= call_back,\n",
    "                              batch_size= 10, epochs= 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del(unet_f2)\n",
    "#del(check_point)\n",
    "#del(history)\n",
    "#del(call_back)\n",
    "#del(train_history_f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Floder3 (train : f02, f03 , test : f01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = floder3[0], floder3[1], floder3[2], floder3[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "preprocessing....\n\ndealing with image....\n\npreprocessing for image finish!\n\ndealing with label....\n\nlabel_to_class_label finish!\n\nFunction label_to_1Hlabel finish!\n\npreprocessing for label finish!\n\n"
    }
   ],
   "source": [
    "train_x, train_y = datapreprocessing(train_x, train_y, resize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "preprocessing....\n\ndealing with image....\n\npreprocessing for image finish!\n\ndealing with label....\n\nlabel_to_class_label finish!\n\nFunction label_to_1Hlabel finish!\n\npreprocessing for label finish!\n\n"
    }
   ],
   "source": [
    "test_x, test_y = datapreprocessing(test_x, test_y, resize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Function transfer_to_train_data finish!\n\n"
    }
   ],
   "source": [
    "train_x = transfer_to_train_data(train_x, (train_x.shape[0], train_x.shape[1],train_x.shape[2],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Function transfer_to_train_data finish!\n\n"
    }
   ],
   "source": [
    "test_x = transfer_to_train_data(test_x, (test_x.shape[0], test_x.shape[1],test_x.shape[2],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = History()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_back = [checkpoint, history]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput (InputLayer)              (None, 672, 224, 1)  0                                            \n__________________________________________________________________________________________________\nc_1_conv1 (Conv2D)              (None, 672, 224, 16) 1312        input[0][0]                      \n__________________________________________________________________________________________________\nc_1_BN1 (BatchNormalization)    (None, 672, 224, 16) 64          c_1_conv1[0][0]                  \n__________________________________________________________________________________________________\nc_1_conv2 (Conv2D)              (None, 672, 224, 16) 20752       c_1_BN1[0][0]                    \n__________________________________________________________________________________________________\nc_1_BN2 (BatchNormalization)    (None, 672, 224, 16) 64          c_1_conv2[0][0]                  \n__________________________________________________________________________________________________\nc_1_maxpool1 (MaxPooling2D)     (None, 336, 112, 16) 0           c_1_BN2[0][0]                    \n__________________________________________________________________________________________________\nc_2_conv1 (Conv2D)              (None, 336, 112, 32) 41504       c_1_maxpool1[0][0]               \n__________________________________________________________________________________________________\nc_2_BN1 (BatchNormalization)    (None, 336, 112, 32) 128         c_2_conv1[0][0]                  \n__________________________________________________________________________________________________\nc_2_conv2 (Conv2D)              (None, 336, 112, 32) 82976       c_2_BN1[0][0]                    \n__________________________________________________________________________________________________\nc_2_BN2 (BatchNormalization)    (None, 336, 112, 32) 128         c_2_conv2[0][0]                  \n__________________________________________________________________________________________________\nc_2_maxpool1 (MaxPooling2D)     (None, 168, 56, 32)  0           c_2_BN2[0][0]                    \n__________________________________________________________________________________________________\nc_3_conv1 (Conv2D)              (None, 168, 56, 64)  165952      c_2_maxpool1[0][0]               \n__________________________________________________________________________________________________\nc_3_BN1 (BatchNormalization)    (None, 168, 56, 64)  256         c_3_conv1[0][0]                  \n__________________________________________________________________________________________________\nc_3_conv2 (Conv2D)              (None, 168, 56, 64)  331840      c_3_BN1[0][0]                    \n__________________________________________________________________________________________________\nc_3_BN2 (BatchNormalization)    (None, 168, 56, 64)  256         c_3_conv2[0][0]                  \n__________________________________________________________________________________________________\nc_3_maxpool1 (MaxPooling2D)     (None, 84, 28, 64)   0           c_3_BN2[0][0]                    \n__________________________________________________________________________________________________\nc_4_conv1 (Conv2D)              (None, 84, 28, 128)  663680      c_3_maxpool1[0][0]               \n__________________________________________________________________________________________________\nc_4_BN1 (BatchNormalization)    (None, 84, 28, 128)  512         c_4_conv1[0][0]                  \n__________________________________________________________________________________________________\nc_4_conv2 (Conv2D)              (None, 84, 28, 128)  1327232     c_4_BN1[0][0]                    \n__________________________________________________________________________________________________\nc_4_BN2 (BatchNormalization)    (None, 84, 28, 128)  512         c_4_conv2[0][0]                  \n__________________________________________________________________________________________________\nc_4_maxpool1 (MaxPooling2D)     (None, 42, 14, 128)  0           c_4_BN2[0][0]                    \n__________________________________________________________________________________________________\nb_conv1 (Conv2D)                (None, 42, 14, 256)  2654464     c_4_maxpool1[0][0]               \n__________________________________________________________________________________________________\nb_BN1 (BatchNormalization)      (None, 42, 14, 256)  1024        b_conv1[0][0]                    \n__________________________________________________________________________________________________\nb_conv2 (Conv2D)                (None, 42, 14, 256)  5308672     b_BN1[0][0]                      \n__________________________________________________________________________________________________\nb_BN2 (BatchNormalization)      (None, 42, 14, 256)  1024        b_conv2[0][0]                    \n__________________________________________________________________________________________________\ne_1_Tconv (Conv2DTranspose)     (None, 84, 28, 128)  2654336     b_BN2[0][0]                      \n__________________________________________________________________________________________________\nconcatenate (Concatenate)       (None, 84, 28, 256)  0           c_4_BN2[0][0]                    \n                                                                 e_1_Tconv[0][0]                  \n__________________________________________________________________________________________________\ne_1_conv1 (Conv2D)              (None, 84, 28, 128)  2654336     concatenate[0][0]                \n__________________________________________________________________________________________________\ne_1_BN1 (BatchNormalization)    (None, 84, 28, 128)  512         e_1_conv1[0][0]                  \n__________________________________________________________________________________________________\ne_1_conv2 (Conv2D)              (None, 84, 28, 128)  1327232     e_1_BN1[0][0]                    \n__________________________________________________________________________________________________\ne_1_BN2 (BatchNormalization)    (None, 84, 28, 128)  512         e_1_conv2[0][0]                  \n__________________________________________________________________________________________________\ne_2_Tconv (Conv2DTranspose)     (None, 168, 56, 64)  663616      e_1_BN2[0][0]                    \n__________________________________________________________________________________________________\nconcatenate_1 (Concatenate)     (None, 168, 56, 128) 0           c_3_BN2[0][0]                    \n                                                                 e_2_Tconv[0][0]                  \n__________________________________________________________________________________________________\ne_2_conv1 (Conv2D)              (None, 168, 56, 64)  663616      concatenate_1[0][0]              \n__________________________________________________________________________________________________\ne_2_BN1 (BatchNormalization)    (None, 168, 56, 64)  256         e_2_conv1[0][0]                  \n__________________________________________________________________________________________________\ne_2_conv2 (Conv2D)              (None, 168, 56, 64)  331840      e_2_BN1[0][0]                    \n__________________________________________________________________________________________________\ne_2_BN2 (BatchNormalization)    (None, 168, 56, 64)  256         e_2_conv2[0][0]                  \n__________________________________________________________________________________________________\ne_3_Tconv (Conv2DTranspose)     (None, 336, 112, 32) 165920      e_2_BN2[0][0]                    \n__________________________________________________________________________________________________\nconcatenate_2 (Concatenate)     (None, 336, 112, 64) 0           c_2_BN2[0][0]                    \n                                                                 e_3_Tconv[0][0]                  \n__________________________________________________________________________________________________\ne_3_conv1 (Conv2D)              (None, 336, 112, 32) 165920      concatenate_2[0][0]              \n__________________________________________________________________________________________________\ne_3_BN1 (BatchNormalization)    (None, 336, 112, 32) 128         e_3_conv1[0][0]                  \n__________________________________________________________________________________________________\ne_3_conv2 (Conv2D)              (None, 336, 112, 32) 82976       e_3_BN1[0][0]                    \n__________________________________________________________________________________________________\ne_3_BN2 (BatchNormalization)    (None, 336, 112, 32) 128         e_3_conv2[0][0]                  \n__________________________________________________________________________________________________\ne_4_Tconv (Conv2DTranspose)     (None, 672, 224, 16) 41488       e_3_BN2[0][0]                    \n__________________________________________________________________________________________________\nconcatenate_3 (Concatenate)     (None, 672, 224, 32) 0           c_1_BN2[0][0]                    \n                                                                 e_4_Tconv[0][0]                  \n__________________________________________________________________________________________________\ne_4_conv1 (Conv2D)              (None, 672, 224, 16) 41488       concatenate_3[0][0]              \n__________________________________________________________________________________________________\ne_4_BN1 (BatchNormalization)    (None, 672, 224, 16) 64          e_4_conv1[0][0]                  \n__________________________________________________________________________________________________\ne_4_conv2 (Conv2D)              (None, 672, 224, 16) 20752       e_4_BN1[0][0]                    \n__________________________________________________________________________________________________\ne_4_BN2 (BatchNormalization)    (None, 672, 224, 16) 64          e_4_conv2[0][0]                  \n__________________________________________________________________________________________________\nconv2d (Conv2D)                 (None, 672, 224, 2)  34          e_4_BN2[0][0]                    \n==================================================================================================\nTotal params: 19,417,826\nTrainable params: 19,414,882\nNon-trainable params: 2,944\n__________________________________________________________________________________________________\nNone\n"
    }
   ],
   "source": [
    "unet_f3 = u_net((672,224,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "0.0310 - val_dice_coef: 0.9690\n\nEpoch 00901: val_loss improved from 0.03116 to 0.03102, saving model to best_pretrain_weights.h5\nEpoch 902/1000\n40/40 [==============================] - 4s 98ms/step - loss: 0.0038 - dice_coef: 0.9962 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00902: val_loss did not improve from 0.03102\nEpoch 903/1000\n40/40 [==============================] - 4s 101ms/step - loss: 0.0039 - dice_coef: 0.9961 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00903: val_loss did not improve from 0.03102\nEpoch 904/1000\n40/40 [==============================] - 4s 106ms/step - loss: 0.0040 - dice_coef: 0.9960 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00904: val_loss did not improve from 0.03102\nEpoch 905/1000\n40/40 [==============================] - 4s 103ms/step - loss: 0.0039 - dice_coef: 0.9961 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00905: val_loss did not improve from 0.03102\nEpoch 906/1000\n40/40 [==============================] - 4s 102ms/step - loss: 0.0039 - dice_coef: 0.9961 - val_loss: 0.0314 - val_dice_coef: 0.9686\n\nEpoch 00906: val_loss did not improve from 0.03102\nEpoch 907/1000\n40/40 [==============================] - 4s 108ms/step - loss: 0.0040 - dice_coef: 0.9960 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00907: val_loss did not improve from 0.03102\nEpoch 908/1000\n40/40 [==============================] - 4s 101ms/step - loss: 0.0039 - dice_coef: 0.9961 - val_loss: 0.0310 - val_dice_coef: 0.9690\n\nEpoch 00908: val_loss did not improve from 0.03102\nEpoch 909/1000\n40/40 [==============================] - 4s 106ms/step - loss: 0.0039 - dice_coef: 0.9961 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00909: val_loss did not improve from 0.03102\nEpoch 910/1000\n40/40 [==============================] - 4s 99ms/step - loss: 0.0039 - dice_coef: 0.9961 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00910: val_loss did not improve from 0.03102\nEpoch 911/1000\n40/40 [==============================] - 4s 102ms/step - loss: 0.0038 - dice_coef: 0.9962 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00911: val_loss did not improve from 0.03102\nEpoch 912/1000\n40/40 [==============================] - 4s 101ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00912: val_loss did not improve from 0.03102\nEpoch 913/1000\n40/40 [==============================] - 4s 101ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0314 - val_dice_coef: 0.9686\n\nEpoch 00913: val_loss did not improve from 0.03102\nEpoch 914/1000\n40/40 [==============================] - 4s 102ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00914: val_loss did not improve from 0.03102\nEpoch 915/1000\n40/40 [==============================] - 4s 101ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00915: val_loss did not improve from 0.03102\nEpoch 916/1000\n40/40 [==============================] - 4s 101ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00916: val_loss did not improve from 0.03102\nEpoch 917/1000\n40/40 [==============================] - 4s 101ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00917: val_loss did not improve from 0.03102\nEpoch 918/1000\n40/40 [==============================] - 4s 102ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00918: val_loss did not improve from 0.03102\nEpoch 919/1000\n40/40 [==============================] - 4s 102ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00919: val_loss did not improve from 0.03102\nEpoch 920/1000\n40/40 [==============================] - 4s 112ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00920: val_loss did not improve from 0.03102\nEpoch 921/1000\n40/40 [==============================] - 4s 100ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00921: val_loss did not improve from 0.03102\nEpoch 922/1000\n40/40 [==============================] - 4s 103ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00922: val_loss did not improve from 0.03102\nEpoch 923/1000\n40/40 [==============================] - 4s 107ms/step - loss: 0.0040 - dice_coef: 0.9960 - val_loss: 0.0310 - val_dice_coef: 0.9690\n\nEpoch 00923: val_loss improved from 0.03102 to 0.03096, saving model to best_pretrain_weights.h5\nEpoch 924/1000\n40/40 [==============================] - 4s 98ms/step - loss: 0.0040 - dice_coef: 0.9960 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00924: val_loss did not improve from 0.03096\nEpoch 925/1000\n40/40 [==============================] - 4s 99ms/step - loss: 0.0040 - dice_coef: 0.9960 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00925: val_loss did not improve from 0.03096\nEpoch 926/1000\n40/40 [==============================] - 4s 111ms/step - loss: 0.0039 - dice_coef: 0.9961 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00926: val_loss did not improve from 0.03096\nEpoch 927/1000\n40/40 [==============================] - 4s 99ms/step - loss: 0.0039 - dice_coef: 0.9961 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00927: val_loss did not improve from 0.03096\nEpoch 928/1000\n40/40 [==============================] - 4s 100ms/step - loss: 0.0039 - dice_coef: 0.9961 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00928: val_loss did not improve from 0.03096\nEpoch 929/1000\n40/40 [==============================] - 4s 105ms/step - loss: 0.0041 - dice_coef: 0.9959 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00929: val_loss did not improve from 0.03096\nEpoch 930/1000\n40/40 [==============================] - 4s 102ms/step - loss: 0.0041 - dice_coef: 0.9959 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00930: val_loss did not improve from 0.03096\nEpoch 931/1000\n40/40 [==============================] - 4s 99ms/step - loss: 0.0039 - dice_coef: 0.9961 - val_loss: 0.0315 - val_dice_coef: 0.9685\n\nEpoch 00931: val_loss did not improve from 0.03096\nEpoch 932/1000\n40/40 [==============================] - 4s 102ms/step - loss: 0.0041 - dice_coef: 0.9959 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00932: val_loss did not improve from 0.03096\nEpoch 933/1000\n40/40 [==============================] - 4s 101ms/step - loss: 0.0041 - dice_coef: 0.9959 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00933: val_loss did not improve from 0.03096\nEpoch 934/1000\n40/40 [==============================] - 4s 101ms/step - loss: 0.0042 - dice_coef: 0.9958 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00934: val_loss did not improve from 0.03096\nEpoch 935/1000\n40/40 [==============================] - 4s 112ms/step - loss: 0.0041 - dice_coef: 0.9959 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00935: val_loss did not improve from 0.03096\nEpoch 936/1000\n40/40 [==============================] - 4s 97ms/step - loss: 0.0042 - dice_coef: 0.9958 - val_loss: 0.0308 - val_dice_coef: 0.9692\n\nEpoch 00936: val_loss improved from 0.03096 to 0.03080, saving model to best_pretrain_weights.h5\nEpoch 937/1000\n40/40 [==============================] - 4s 101ms/step - loss: 0.0041 - dice_coef: 0.9959 - val_loss: 0.0310 - val_dice_coef: 0.9690\n\nEpoch 00937: val_loss did not improve from 0.03080\nEpoch 938/1000\n40/40 [==============================] - 4s 104ms/step - loss: 0.0042 - dice_coef: 0.9958 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00938: val_loss did not improve from 0.03080\nEpoch 939/1000\n40/40 [==============================] - 4s 111ms/step - loss: 0.0040 - dice_coef: 0.9960 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00939: val_loss did not improve from 0.03080\nEpoch 940/1000\n40/40 [==============================] - 4s 100ms/step - loss: 0.0039 - dice_coef: 0.9961 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00940: val_loss did not improve from 0.03080\nEpoch 941/1000\n40/40 [==============================] - 4s 99ms/step - loss: 0.0038 - dice_coef: 0.9962 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00941: val_loss did not improve from 0.03080\nEpoch 942/1000\n40/40 [==============================] - 4s 100ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00942: val_loss did not improve from 0.03080\nEpoch 943/1000\n40/40 [==============================] - 4s 104ms/step - loss: 0.0038 - dice_coef: 0.9962 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00943: val_loss did not improve from 0.03080\nEpoch 944/1000\n40/40 [==============================] - 4s 102ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00944: val_loss did not improve from 0.03080\nEpoch 945/1000\n40/40 [==============================] - 4s 99ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00945: val_loss did not improve from 0.03080\nEpoch 946/1000\n40/40 [==============================] - 4s 112ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00946: val_loss did not improve from 0.03080\nEpoch 947/1000\n40/40 [==============================] - 4s 101ms/step - loss: 0.0037 - dice_coef: 0.9963 - val_loss: 0.0310 - val_dice_coef: 0.9690\n\nEpoch 00947: val_loss did not improve from 0.03080\nEpoch 948/1000\n40/40 [==============================] - 4s 99ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0310 - val_dice_coef: 0.9690\n\nEpoch 00948: val_loss did not improve from 0.03080\nEpoch 949/1000\n40/40 [==============================] - 4s 103ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00949: val_loss did not improve from 0.03080\nEpoch 950/1000\n40/40 [==============================] - 4s 102ms/step - loss: 0.0035 - dice_coef: 0.9965 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00950: val_loss did not improve from 0.03080\nEpoch 951/1000\n40/40 [==============================] - 4s 98ms/step - loss: 0.0035 - dice_coef: 0.9965 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00951: val_loss did not improve from 0.03080\nEpoch 952/1000\n40/40 [==============================] - 4s 105ms/step - loss: 0.0036 - dice_coef: 0.9964 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00952: val_loss did not improve from 0.03080\nEpoch 953/1000\n40/40 [==============================] - 4s 105ms/step - loss: 0.0035 - dice_coef: 0.9965 - val_loss: 0.0313 - val_dice_coef: 0.9687\n\nEpoch 00953: val_loss did not improve from 0.03080\nEpoch 954/1000\n40/40 [==============================] - 4s 99ms/step - loss: 0.0035 - dice_coef: 0.9965 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00954: val_loss did not improve from 0.03080\nEpoch 955/1000\n40/40 [==============================] - 4s 101ms/step - loss: 0.0035 - dice_coef: 0.9965 - val_loss: 0.0310 - val_dice_coef: 0.9690\n\nEpoch 00955: val_loss did not improve from 0.03080\nEpoch 956/1000\n40/40 [==============================] - 4s 99ms/step - loss: 0.0035 - dice_coef: 0.9965 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00956: val_loss did not improve from 0.03080\nEpoch 957/1000\n40/40 [==============================] - 4s 102ms/step - loss: 0.0034 - dice_coef: 0.9966 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00957: val_loss did not improve from 0.03080\nEpoch 958/1000\n40/40 [==============================] - 4s 101ms/step - loss: 0.0035 - dice_coef: 0.9965 - val_loss: 0.0310 - val_dice_coef: 0.9690\n\nEpoch 00958: val_loss did not improve from 0.03080\nEpoch 959/1000\n40/40 [==============================] - 4s 105ms/step - loss: 0.0034 - dice_coef: 0.9966 - val_loss: 0.0310 - val_dice_coef: 0.9690\n\nEpoch 00959: val_loss did not improve from 0.03080\nEpoch 960/1000\n40/40 [==============================] - 4s 104ms/step - loss: 0.0034 - dice_coef: 0.9966 - val_loss: 0.0310 - val_dice_coef: 0.9690\n\nEpoch 00960: val_loss did not improve from 0.03080\nEpoch 961/1000\n40/40 [==============================] - 4s 100ms/step - loss: 0.0034 - dice_coef: 0.9966 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00961: val_loss did not improve from 0.03080\nEpoch 962/1000\n40/40 [==============================] - 4s 102ms/step - loss: 0.0034 - dice_coef: 0.9966 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00962: val_loss did not improve from 0.03080\nEpoch 963/1000\n40/40 [==============================] - 4s 111ms/step - loss: 0.0033 - dice_coef: 0.9967 - val_loss: 0.0309 - val_dice_coef: 0.9691\n\nEpoch 00963: val_loss did not improve from 0.03080\nEpoch 964/1000\n40/40 [==============================] - 4s 99ms/step - loss: 0.0033 - dice_coef: 0.9967 - val_loss: 0.0309 - val_dice_coef: 0.9691\n\nEpoch 00964: val_loss did not improve from 0.03080\nEpoch 965/1000\n40/40 [==============================] - 4s 102ms/step - loss: 0.0033 - dice_coef: 0.9967 - val_loss: 0.0310 - val_dice_coef: 0.9690\n\nEpoch 00965: val_loss did not improve from 0.03080\nEpoch 966/1000\n40/40 [==============================] - 4s 100ms/step - loss: 0.0033 - dice_coef: 0.9967 - val_loss: 0.0310 - val_dice_coef: 0.9690\n\nEpoch 00966: val_loss did not improve from 0.03080\nEpoch 967/1000\n40/40 [==============================] - 4s 104ms/step - loss: 0.0033 - dice_coef: 0.9967 - val_loss: 0.0309 - val_dice_coef: 0.9691\n\nEpoch 00967: val_loss did not improve from 0.03080\nEpoch 968/1000\n40/40 [==============================] - 4s 99ms/step - loss: 0.0034 - dice_coef: 0.9966 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00968: val_loss did not improve from 0.03080\nEpoch 969/1000\n40/40 [==============================] - 4s 102ms/step - loss: 0.0033 - dice_coef: 0.9967 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00969: val_loss did not improve from 0.03080\nEpoch 970/1000\n40/40 [==============================] - 4s 102ms/step - loss: 0.0034 - dice_coef: 0.9966 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00970: val_loss did not improve from 0.03080\nEpoch 971/1000\n40/40 [==============================] - 4s 102ms/step - loss: 0.0034 - dice_coef: 0.9966 - val_loss: 0.0310 - val_dice_coef: 0.9690\n\nEpoch 00971: val_loss did not improve from 0.03080\nEpoch 972/1000\n40/40 [==============================] - 4s 103ms/step - loss: 0.0034 - dice_coef: 0.9966 - val_loss: 0.0309 - val_dice_coef: 0.9691\n\nEpoch 00972: val_loss did not improve from 0.03080\nEpoch 973/1000\n40/40 [==============================] - 5s 114ms/step - loss: 0.0034 - dice_coef: 0.9966 - val_loss: 0.0309 - val_dice_coef: 0.9691\n\nEpoch 00973: val_loss did not improve from 0.03080\nEpoch 974/1000\n40/40 [==============================] - 4s 97ms/step - loss: 0.0034 - dice_coef: 0.9966 - val_loss: 0.0310 - val_dice_coef: 0.9690\n\nEpoch 00974: val_loss did not improve from 0.03080\nEpoch 975/1000\n40/40 [==============================] - 4s 112ms/step - loss: 0.0034 - dice_coef: 0.9966 - val_loss: 0.0310 - val_dice_coef: 0.9690\n\nEpoch 00975: val_loss did not improve from 0.03080\nEpoch 976/1000\n40/40 [==============================] - 4s 100ms/step - loss: 0.0034 - dice_coef: 0.9966 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00976: val_loss did not improve from 0.03080\nEpoch 977/1000\n40/40 [==============================] - 4s 99ms/step - loss: 0.0034 - dice_coef: 0.9966 - val_loss: 0.0310 - val_dice_coef: 0.9690\n\nEpoch 00977: val_loss did not improve from 0.03080\nEpoch 978/1000\n40/40 [==============================] - 4s 101ms/step - loss: 0.0035 - dice_coef: 0.9965 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00978: val_loss did not improve from 0.03080\nEpoch 979/1000\n40/40 [==============================] - 4s 99ms/step - loss: 0.0035 - dice_coef: 0.9965 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00979: val_loss did not improve from 0.03080\nEpoch 980/1000\n40/40 [==============================] - 4s 102ms/step - loss: 0.0035 - dice_coef: 0.9965 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00980: val_loss did not improve from 0.03080\nEpoch 981/1000\n40/40 [==============================] - 4s 109ms/step - loss: 0.0035 - dice_coef: 0.9965 - val_loss: 0.0310 - val_dice_coef: 0.9690\n\nEpoch 00981: val_loss did not improve from 0.03080\nEpoch 982/1000\n40/40 [==============================] - 4s 98ms/step - loss: 0.0034 - dice_coef: 0.9966 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00982: val_loss did not improve from 0.03080\nEpoch 983/1000\n40/40 [==============================] - 4s 100ms/step - loss: 0.0035 - dice_coef: 0.9965 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00983: val_loss did not improve from 0.03080\nEpoch 984/1000\n40/40 [==============================] - 4s 105ms/step - loss: 0.0034 - dice_coef: 0.9966 - val_loss: 0.0309 - val_dice_coef: 0.9691\n\nEpoch 00984: val_loss did not improve from 0.03080\nEpoch 985/1000\n40/40 [==============================] - 4s 104ms/step - loss: 0.0034 - dice_coef: 0.9966 - val_loss: 0.0309 - val_dice_coef: 0.9691\n\nEpoch 00985: val_loss did not improve from 0.03080\nEpoch 986/1000\n40/40 [==============================] - 4s 100ms/step - loss: 0.0034 - dice_coef: 0.9966 - val_loss: 0.0309 - val_dice_coef: 0.9691\n\nEpoch 00986: val_loss did not improve from 0.03080\nEpoch 987/1000\n40/40 [==============================] - 4s 103ms/step - loss: 0.0034 - dice_coef: 0.9966 - val_loss: 0.0310 - val_dice_coef: 0.9690\n\nEpoch 00987: val_loss did not improve from 0.03080\nEpoch 988/1000\n40/40 [==============================] - 4s 100ms/step - loss: 0.0034 - dice_coef: 0.9966 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00988: val_loss did not improve from 0.03080\nEpoch 989/1000\n40/40 [==============================] - 4s 100ms/step - loss: 0.0033 - dice_coef: 0.9967 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00989: val_loss did not improve from 0.03080\nEpoch 990/1000\n40/40 [==============================] - 4s 109ms/step - loss: 0.0033 - dice_coef: 0.9967 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00990: val_loss did not improve from 0.03080\nEpoch 991/1000\n40/40 [==============================] - 4s 106ms/step - loss: 0.0033 - dice_coef: 0.9967 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00991: val_loss did not improve from 0.03080\nEpoch 992/1000\n40/40 [==============================] - 4s 101ms/step - loss: 0.0033 - dice_coef: 0.9967 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00992: val_loss did not improve from 0.03080\nEpoch 993/1000\n40/40 [==============================] - 4s 100ms/step - loss: 0.0033 - dice_coef: 0.9967 - val_loss: 0.0312 - val_dice_coef: 0.9688\n\nEpoch 00993: val_loss did not improve from 0.03080\nEpoch 994/1000\n40/40 [==============================] - 4s 102ms/step - loss: 0.0033 - dice_coef: 0.9967 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00994: val_loss did not improve from 0.03080\nEpoch 995/1000\n40/40 [==============================] - 4s 99ms/step - loss: 0.0033 - dice_coef: 0.9967 - val_loss: 0.0310 - val_dice_coef: 0.9690\n\nEpoch 00995: val_loss did not improve from 0.03080\nEpoch 996/1000\n40/40 [==============================] - 4s 99ms/step - loss: 0.0033 - dice_coef: 0.9967 - val_loss: 0.0310 - val_dice_coef: 0.9690\n\nEpoch 00996: val_loss did not improve from 0.03080\nEpoch 997/1000\n40/40 [==============================] - 4s 105ms/step - loss: 0.0033 - dice_coef: 0.9967 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00997: val_loss did not improve from 0.03080\nEpoch 998/1000\n40/40 [==============================] - 5s 117ms/step - loss: 0.0033 - dice_coef: 0.9967 - val_loss: 0.0311 - val_dice_coef: 0.9689\n\nEpoch 00998: val_loss did not improve from 0.03080\nEpoch 999/1000\n40/40 [==============================] - 4s 100ms/step - loss: 0.0033 - dice_coef: 0.9967 - val_loss: 0.0308 - val_dice_coef: 0.9692\n\nEpoch 00999: val_loss did not improve from 0.03080\nEpoch 1000/1000\n40/40 [==============================] - 4s 98ms/step - loss: 0.0033 - dice_coef: 0.9967 - val_loss: 0.0310 - val_dice_coef: 0.9690\n\nEpoch 01000: val_loss did not improve from 0.03080\n"
    }
   ],
   "source": [
    "train_history_f3 = unet_f3.fit(x = train_x, y = train_y, validation_data = (test_x, test_y), callbacks= call_back,\n",
    "                              batch_size= 10, epochs= 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}